{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT4dy82Rf-v1"
      },
      "source": [
        "# Installing requirements (for colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4khPQ2_Kf-v1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d2bcdf9-1294-4fc3-b173-03c8cacbb862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.7).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install python3.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m0y9RfWif-v2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07599d4a-cba2-4e7c-d1b4-0ac07e903e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==2.0.3\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting numpy==1.25.2\n",
            "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scipy==1.11.4\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting swig==4.2.1\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting ufal.pybox2d==2.3.10.3\n",
            "  Downloading ufal.pybox2d-2.3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (416 bytes)\n",
            "Requirement already satisfied: gym==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Collecting pygame==2.5.2\n",
            "  Downloading pygame-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2024.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ufal.pybox2d-2.3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygame-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ufal.pybox2d, swig, lit, pygame, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, scipy, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 numpy-1.25.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pandas-2.0.3 pygame-2.5.2 scipy-1.11.4 swig-4.2.1 torch-2.0.1 triton-2.0.0 ufal.pybox2d-2.3.10.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b1d8bff377a14714bed8e13bc138545d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pandas==2.0.3 numpy==1.25.2 scipy==1.11.4 swig==4.2.1 ufal.pybox2d==2.3.10.3 gym==0.25.2 pygame==2.5.2 tqdm torch==2.0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkdfX6yAPbPm"
      },
      "source": [
        "# Cloning git (for colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kVZs5loNPbPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52b2a10-44da-4edc-8b10-ecc6846b346b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Reversal-Generative-Reinforcement-Learning'...\n",
            "remote: Enumerating objects: 3203, done.\u001b[K\n",
            "remote: Counting objects: 100% (805/805), done.\u001b[K\n",
            "remote: Compressing objects: 100% (312/312), done.\u001b[K\n",
            "remote: Total 3203 (delta 536), reused 707 (delta 489), pack-reused 2398 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3203/3203), 19.20 MiB | 7.99 MiB/s, done.\n",
            "Resolving deltas: 100% (2263/2263), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Brownwang0426/Reversal-Generative-Reinforcement-Learning.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2UlIqB3PbPo"
      },
      "source": [
        "# Changing directory (for colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hj-G_J3dPbPo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/Reversal-Generative-Reinforcement-Learning')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kEiLW6f-v2"
      },
      "source": [
        "# Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mVWhBy17f-v3"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.special import softmax\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "\n",
        "import csv\n",
        "\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "import gc\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import itertools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7Oa0SxAx5SFy"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElhExcVoSxd7"
      },
      "source": [
        "# Checking cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Aj5V_vlwSxd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7871c426-27bc-4bcc-beda-1cc2949e67c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0: Tesla T4\n",
            "using cuda...\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    device_index = 0\n",
        "    device = torch.device(f\"cuda:{device_index}\")\n",
        "    print('using cuda...')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('using cpu...')\n",
        "assert device != torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SlwYjPr7CYJd"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7r-W0IeGBR0"
      },
      "source": [
        "# Control board\n",
        "\n",
        "Crucial configurations regarding how your agent will learn in the environment. The meanings are as follow:\n",
        "(the configs starting with ⚠️ are what we suggest you must tune according to your specific need in your task)\n",
        "(the configs starting with ◀️ are what we suggest you to play with to see the effect)\n",
        "\n",
        "| Configs   | Type   | Description                                                                 |\n",
        "|------------|--------|-----------------------------------------------------------------------------|\n",
        "| ⚠️game_name  | STR| The name of the environment.                                |\n",
        "| ⚠️max_steps_for_each_episode | +INT | The maximun steps that the agent will go through while not done. In some environments, it is crucial to increase your \"max_steps_for_each_episode\" so that your agent can \"live long enough\" to obatin some better rewards to gradually and heuristically learn better strategy.                    |\n",
        "| ◀️ensemble_size  | +INT | The size of the neural ensemble which the agent is comprised of. The bigger, the better, but the longer training time without parallel training. :-D                  |\n",
        "| ⚠️state_size  | +INT | The size of the state as input data.                    |\n",
        "| ⚠️hidden_size   | +INT |The size of the hidden layers. We suggest hidden_size >= state_size.           |\n",
        "| ⚠️action_size   | +INT | The size of action per step as input data.   |\n",
        "| ⚠️time_size  | +INT |The length of the sequence of actions. Namely, how many steps in the future the agent will predict or use to discern the present best action.                |\n",
        "| ⚠️reward_size  | +INT |The size of the reward as output data.                          |\n",
        "| ⚠️neural_type  | STR |  [**`rnn`**, **`gru`**, **`lstm`**, **`rnn_att`**] The type of neural network you prefer. For now, we support rnn, gru, lstm, and rnn_att (recurrent attention). More to come in the future (or you can build one yourself :-D in the models repository).           |\n",
        "| ⚠️num_layers  | +INT |The number of layers in rnn, gru, lstm, and rnn_att (recurrent attention). We suggest no less than 3 (>= 3) to provide more flexibility and memory capacity for neural networks.                         |\n",
        "| ⚠️num_heads  | +INT/None |The number of heads in multi-head attention (Should be able to devide hidden_size) (Should be None for non-attention neural_type).                         |\n",
        "| hidden_activation  | STR | [**`relu`**, **`leaky_relu`**, **`sigmoid`**, **`tanh`**] The type of activation function in the hidden layers.              |\n",
        "| output_activation  | STR | [**`relu`**, **`leaky_relu`**, **`sigmoid`**, **`tanh`**] The type of activation function in the output layer.                      |\n",
        "| shift  | 0/±FLOAT |The value in f(x+shift) where f(x) is activation function in the output layer. This value is interesting. If this value is negatively large, the agent will act more conservatively and prone to exploit known strategy. If this value is positively large, the agent to act more radically and prone to explore all possible strategies before settling down.      |\n",
        "| init   | STR | [**`random_normal`**, **`random_uniform`**, **`xavier_normal`**, **`xavier_uniform`**, **`glorot_normal`**, **`glorot_uniform`**] The initialization method you prefer.                          |\n",
        "| opti   | STR | [**`adam`**, **`sgd`**, **`rmsprop`**]  The optimization method you prefer.             |\n",
        "| loss  | STR | [**`mean_squared_error`**, **`binary_crossentropy`**] The loss or error function you prefer.                           |\n",
        "| bias  | BOLEAN |Whether you want add bias.                          |\n",
        "| drop_rate   | 0/+FLOAT |The drop-rate for drop-out.              |\n",
        "| ⚠️alpha   | 0/+FLOAT |The learning rate for neural networks weight matrices.                           |\n",
        "| ⚠️iteration_for_learning   | +INT |The iteration for learning.              |\n",
        "| load_pre_model  | BOLEAN |Whether you want to load previous trained model.                          |\n",
        "| noise_t  |  +INT |The times applying gaussian noise to the initializated actions of the agent, similar to diffusion model's adding gaussian noise.          |\n",
        "| ⚠️noise_r  |  0/+FLOAT |The noise range to the initializated actions of the agent. The higher the value is, the more exploration-oriented the agent will be.                    |\n",
        "| ⚠️noise_r_oscillation  |  +INT |The interval for which noise range will oscillate between noise_r and a very small number like 0.000001 to encourage agent to balance eploration and exploitation.                    |\n",
        "| ⚠️beta  |  0/+FLOAT |The updating rate for updating actions of the agent.              |\n",
        "| ⚠️iteration_for_deducing  |  +INT |The iteration for updating actions of the agent.                           |\n",
        "| episode_for_training  | +INT |How many epsiodes will your agent run in the training mode where your agent will learn offline.              |\n",
        "| chunk_size  | +INT |The maximum chunk size for sequentializing state, action, reward. We suggest chunk_size <= time_size.      |\n",
        "| batch_size_for_offline_learning  |+INT | After how many epsodes will your agent start learning from experience buffer.                           |\n",
        "| PER_epsilon  | 0/+FLOAT |The epsilon for prioritized experience replay.              |\n",
        "| PER_exponent  | 0/+FLOAT |The expoenet for prioritized experience replay.                           |\n",
        "| episode_for_testing  | +INT |How many epsiodes will your agent run in the testing mode where your agent will not learn offline.                        |\n",
        "| render_for_human  | BOLEAN | Wether you want to render the visual result for each step in the testing mode.              |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0ZJ8yAtPbPw"
      },
      "source": [
        "## frozen lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SMEvmlwvPbPw"
      },
      "outputs": [],
      "source": [
        "game_name =  'FrozenLake-v1'        #⚠️  gym.make(game_name, is_slippery=False, map_name=\"4x4\")\n",
        "max_steps_for_each_episode = 25     #⚠️\n",
        "\n",
        "\n",
        "ensemble_size = 5                   #◀️\n",
        "state_size =  16                    #⚠️\n",
        "hidden_size = 100                   #⚠️\n",
        "action_size = 4                     #⚠️\n",
        "time_size = 8                       #⚠️\n",
        "reward_size = 100                   #⚠️\n",
        "neural_type = 'gru'                 #⚠️\n",
        "num_layers = 3                      #⚠️\n",
        "num_heads = None                    #⚠️\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'sigmoid'\n",
        "shift = 0.0\n",
        "init = \"random_normal\"\n",
        "opti = 'sgd'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.1                         #⚠️\n",
        "iteration_for_learning = 1000       #⚠️\n",
        "load_pre_model = False\n",
        "\n",
        "\n",
        "noise_t = 1                         #⚠️\n",
        "noise_r = 0.1                       #⚠️\n",
        "noise_r_oscillation = 10            #⚠️\n",
        "beta = 0.1                          #⚠️\n",
        "iteration_for_deducing = 100        #⚠️\n",
        "\n",
        "\n",
        "episode_for_training = 100000\n",
        "chunk_size = time_size\n",
        "batch_size_for_offline_learning = 1\n",
        "PER_epsilon = 0.000001\n",
        "PER_exponent = 5\n",
        "\n",
        "\n",
        "episode_for_testing = 100\n",
        "render_for_human = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KASBb8wJPbPw"
      },
      "source": [
        "## blackjack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xH9VANzcPbPw"
      },
      "outputs": [],
      "source": [
        "game_name = 'Blackjack-v1'          #⚠️\n",
        "max_steps_for_each_episode = 10     #⚠️\n",
        "\n",
        "\n",
        "ensemble_size = 5                   #◀️\n",
        "state_size =  201                   #⚠️\n",
        "hidden_size = 250                   #⚠️\n",
        "action_size = 2                     #⚠️\n",
        "time_size = 5                       #⚠️\n",
        "reward_size = 100                   #⚠️\n",
        "neural_type = 'gru'                 #⚠️\n",
        "num_layers = 3                      #⚠️\n",
        "num_heads = None                    #⚠️\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'sigmoid'\n",
        "shift = 0.0\n",
        "init = \"random_normal\"\n",
        "opti = 'sgd'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.1                         #⚠️\n",
        "iteration_for_learning = 1000       #⚠️\n",
        "load_pre_model = False\n",
        "\n",
        "\n",
        "noise_t = 1\n",
        "noise_r = 0.1                       #⚠️\n",
        "noise_r_oscillation = 10            #⚠️\n",
        "beta = 0.1                          #⚠️\n",
        "iteration_for_deducing = 100        #⚠️\n",
        "\n",
        "\n",
        "episode_for_training = 100000\n",
        "chunk_size = time_size\n",
        "batch_size_for_offline_learning = 1\n",
        "PER_epsilon = 0.000001\n",
        "PER_exponent = 5\n",
        "\n",
        "\n",
        "episode_for_testing = 100\n",
        "render_for_human = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgCIHGHWPbPx"
      },
      "source": [
        "## cartpole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZlQB_D3UPbPx"
      },
      "outputs": [],
      "source": [
        "game_name = 'CartPole-v1'           #⚠️\n",
        "max_steps_for_each_episode = 2000   #⚠️\n",
        "\n",
        "\n",
        "ensemble_size = 10                  #◀️\n",
        "state_size =  400                   #⚠️\n",
        "hidden_size = 400                   #⚠️\n",
        "action_size = 2                     #⚠️\n",
        "time_size = 25                      #⚠️\n",
        "reward_size = 100                   #⚠️\n",
        "neural_type = 'gru'                 #⚠️\n",
        "num_layers = 3                      #⚠️\n",
        "num_heads = None                    #⚠️\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'sigmoid'\n",
        "shift = 0.0\n",
        "init = \"random_normal\"\n",
        "opti = 'sgd'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.1                         #⚠️\n",
        "iteration_for_learning = 1000       #⚠️\n",
        "load_pre_model = False\n",
        "\n",
        "\n",
        "noise_t = 1                         #⚠️\n",
        "noise_r = 0.1                       #⚠️\n",
        "noise_r_oscillation = 10            #⚠️\n",
        "beta = 0.1                          #⚠️\n",
        "iteration_for_deducing = 100        #⚠️\n",
        "\n",
        "\n",
        "episode_for_training = 100000\n",
        "chunk_size = time_size\n",
        "batch_size_for_offline_learning = 1\n",
        "PER_epsilon = 0.000001\n",
        "PER_exponent = 5\n",
        "\n",
        "\n",
        "episode_for_testing = 100\n",
        "render_for_human = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MiLL2IAPbPx"
      },
      "source": [
        "## mountain car"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "m3uFeGuePbPx"
      },
      "outputs": [],
      "source": [
        "game_name =  'MountainCar-v0'       #⚠️\n",
        "max_steps_for_each_episode = 200    #⚠️\n",
        "\n",
        "\n",
        "ensemble_size = 10                  #◀️\n",
        "state_size =  200                   #⚠️\n",
        "hidden_size = 200                   #⚠️\n",
        "action_size = 3                     #⚠️\n",
        "time_size = 50                      #⚠️\n",
        "reward_size = 100                   #⚠️\n",
        "neural_type = 'gru'                 #⚠️\n",
        "num_layers = 3                      #⚠️\n",
        "num_heads = None                    #⚠️\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'sigmoid'\n",
        "shift = 0.0\n",
        "init = \"random_normal\"\n",
        "opti = 'sgd'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.1                         #⚠️\n",
        "iteration_for_learning = 1000       #⚠️\n",
        "load_pre_model = False\n",
        "\n",
        "\n",
        "noise_t = 1\n",
        "noise_r = 0.1                       #⚠️\n",
        "noise_r_oscillation = 10            #⚠️\n",
        "beta = 0.1                          #⚠️\n",
        "iteration_for_deducing = 100        #⚠️\n",
        "\n",
        "\n",
        "episode_for_training = 100000\n",
        "chunk_size = time_size\n",
        "batch_size_for_offline_learning = 1\n",
        "PER_epsilon = 0.000001\n",
        "PER_exponent = 5\n",
        "\n",
        "\n",
        "episode_for_testing = 100\n",
        "render_for_human = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75C-eQ0QPbPy"
      },
      "source": [
        "## acrobot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xQsfQiPsPbPy"
      },
      "outputs": [],
      "source": [
        "game_name = 'Acrobot-v1'            #⚠️\n",
        "max_steps_for_each_episode = 200    #⚠️\n",
        "\n",
        "\n",
        "ensemble_size = 5                   #◀️\n",
        "state_size =  600                   #⚠️\n",
        "hidden_size = 600                   #⚠️\n",
        "action_size = 3                     #⚠️\n",
        "time_size = 50                      #⚠️\n",
        "reward_size = 100                   #⚠️\n",
        "neural_type = 'gru'                 #⚠️\n",
        "num_layers = 3                      #⚠️\n",
        "num_heads = None                    #⚠️\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'sigmoid'\n",
        "shift = 0.0\n",
        "init = \"random_normal\"\n",
        "opti = 'sgd'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.1                         #⚠️\n",
        "iteration_for_learning = 1000       #⚠️\n",
        "load_pre_model = False\n",
        "\n",
        "\n",
        "noise_t = 1\n",
        "noise_r = 0.1                       #⚠️\n",
        "noise_r_oscillation = 10            #⚠️\n",
        "beta = 0.1                          #⚠️\n",
        "iteration_for_deducing = 100        #⚠️\n",
        "\n",
        "\n",
        "episode_for_training = 100000\n",
        "chunk_size = time_size\n",
        "batch_size_for_offline_learning = 1\n",
        "PER_epsilon = 0.000001\n",
        "PER_exponent = 5\n",
        "\n",
        "\n",
        "episode_for_testing = 100\n",
        "render_for_human = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yi3S50oPbPy"
      },
      "source": [
        "## lunar lander"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_FUT8oRiPbPz"
      },
      "outputs": [],
      "source": [
        "game_name = \"LunarLander-v2\"        #⚠️\n",
        "max_steps_for_each_episode = 200    #⚠️\n",
        "\n",
        "\n",
        "ensemble_size = 5                   #◀️\n",
        "state_size =  800                   #⚠️\n",
        "hidden_size = 800                   #⚠️\n",
        "action_size = 4                     #⚠️\n",
        "time_size = 50                      #⚠️\n",
        "reward_size = 250                   #⚠️\n",
        "neural_type = 'gru'                 #⚠️\n",
        "num_layers = 3                      #⚠️\n",
        "num_heads = None                    #⚠️\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'sigmoid'\n",
        "shift = 0.0\n",
        "init = \"random_normal\"\n",
        "opti = 'sgd'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.1                         #⚠️\n",
        "iteration_for_learning = 1000       #⚠️\n",
        "load_pre_model = False\n",
        "\n",
        "\n",
        "noise_t = 1                         #⚠️\n",
        "noise_r = 0.1                       #⚠️\n",
        "noise_r_oscillation = 10            #⚠️\n",
        "beta = 0.1                          #⚠️\n",
        "iteration_for_deducing = 100        #⚠️\n",
        "\n",
        "\n",
        "episode_for_training = 100000\n",
        "chunk_size = time_size\n",
        "batch_size_for_offline_learning = 1\n",
        "PER_epsilon = 0.000001\n",
        "PER_exponent = 5\n",
        "\n",
        "\n",
        "episode_for_testing = 100\n",
        "render_for_human = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wyup25fPbPz"
      },
      "source": [
        "## your present config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2qFfB3E5PbPz"
      },
      "outputs": [],
      "source": [
        "game_name =  'FrozenLake-v1'        #⚠️\n",
        "max_steps_for_each_episode = 25     #⚠️\n",
        "\n",
        "\n",
        "ensemble_size = 5                   #◀️\n",
        "state_size =  16                    #⚠️\n",
        "hidden_size = 100                   #⚠️\n",
        "action_size = 4                     #⚠️\n",
        "time_size = 8                       #⚠️\n",
        "reward_size = 100                   #⚠️\n",
        "neural_type = 'gru'                 #⚠️\n",
        "num_layers = 3                      #⚠️\n",
        "num_heads = None                    #⚠️\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'sigmoid'\n",
        "shift = 0.0\n",
        "init = \"random_normal\"\n",
        "opti = 'sgd'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.1                         #⚠️\n",
        "iteration_for_learning = 1000       #⚠️\n",
        "load_pre_model = False\n",
        "\n",
        "\n",
        "noise_t = 1                         #⚠️\n",
        "noise_r = 0.1                       #⚠️\n",
        "noise_r_oscillation = 10            #⚠️\n",
        "beta = 0.1                          #⚠️\n",
        "iteration_for_deducing = 100        #⚠️\n",
        "\n",
        "\n",
        "episode_for_training = 100000\n",
        "chunk_size = time_size\n",
        "batch_size_for_offline_learning = 1\n",
        "PER_epsilon = 0.000001\n",
        "PER_exponent = 5\n",
        "\n",
        "\n",
        "episode_for_testing = 100\n",
        "render_for_human = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "e2pcs2TbPbPz"
      },
      "outputs": [],
      "source": [
        "suffix                      = f\"game={game_name}_type={neural_type}_ensemble={ensemble_size:05d}_drop={drop_rate:.5f}_learn={iteration_for_learning:05d}_interval={batch_size_for_offline_learning:05d}_deduce={iteration_for_deducing:05d}\"\n",
        "directory                   = f'./result/{game_name}/'\n",
        "model_directory             = f'./result/{game_name}/model_{suffix}'+'_%s.h5'\n",
        "performance_log_directory   = f'./result/{game_name}/performace_log_{suffix}.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TcwUHixPbPz"
      },
      "source": [
        "# Importing local modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rUk1dHbfPbPz"
      },
      "outputs": [],
      "source": [
        "if   game_name == 'FrozenLake-v1':\n",
        "    from envs.env_frozenlake   import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "elif   game_name == 'Blackjack-v1':\n",
        "    from envs.env_blackjack   import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "elif   game_name == 'CartPole-v1':\n",
        "    from envs.env_cartpole    import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "elif game_name == 'MountainCar-v0':\n",
        "    from envs.env_mountaincar import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "elif game_name == 'MountainCarContinuous-v0':\n",
        "    from envs.env_mountaincar_continuous import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "elif game_name == 'Acrobot-v1':\n",
        "    from envs.env_acrobot import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "elif game_name == \"Pendulum-v1\":\n",
        "    from envs.env_pendulum import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "elif game_name == \"LunarLander-v2\":\n",
        "    from envs.env_lunarlander import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "elif game_name == 'BipedalWalker-v3':\n",
        "    from envs.env_bipedalwalker import vectorizing_state, vectorizing_action, vectorizing_reward\n",
        "else:\n",
        "   raise RuntimeError('missing env functions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ErBxWJc2PbP0"
      },
      "outputs": [],
      "source": [
        "if neural_type == 'rnn_att':\n",
        "    from models.model_rnn_att import build_model\n",
        "    from utils.util_rnn_att   import initialize_pre_activated_actions, \\\n",
        "                                 update_pre_activated_actions, \\\n",
        "                                 sequentialize, \\\n",
        "                                 update_model,\\\n",
        "                                 save_performance_to_csv\n",
        "else:\n",
        "    from models.model_rnn import build_model\n",
        "    from utils.util_rnn_  import initialize_pre_activated_actions, \\\n",
        "                                 update_pre_activated_actions, \\\n",
        "                                 sequentialize, \\\n",
        "                                 update_model,\\\n",
        "                                 save_performance_to_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iigp5dSf-v5"
      },
      "source": [
        "# Deducing -> Learning\n",
        "Training mode where your agent will learn offline. You can see here how your agent learn overtime and improve its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A6aXOy7SxeE"
      },
      "source": [
        "Creating or loading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qsXAP3sNf-v8"
      },
      "outputs": [],
      "source": [
        "\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "if load_pre_model == False:\n",
        "\n",
        "    model_list = []\n",
        "    for _ in range(ensemble_size):\n",
        "        model = build_model(state_size,\n",
        "                            hidden_size,\n",
        "                            action_size,\n",
        "                            time_size,\n",
        "                            reward_size,\n",
        "                            neural_type,\n",
        "                            num_layers,\n",
        "                            num_heads,\n",
        "                            hidden_activation,\n",
        "                            output_activation,\n",
        "                            shift,\n",
        "                            init,\n",
        "                            opti,\n",
        "                            loss,\n",
        "                            bias,\n",
        "                            drop_rate,\n",
        "                            alpha)\n",
        "        model.to(device)\n",
        "        model_list.append(model)\n",
        "\n",
        "elif load_pre_model == True:\n",
        "\n",
        "    model_list = []\n",
        "    for _ in range(ensemble_size):\n",
        "        model = build_model(state_size,\n",
        "                            hidden_size,\n",
        "                            action_size,\n",
        "                            time_size,\n",
        "                            reward_size,\n",
        "                            neural_type,\n",
        "                            num_layers,\n",
        "                            num_heads,\n",
        "                            hidden_activation,\n",
        "                            output_activation,\n",
        "                            shift,\n",
        "                            init,\n",
        "                            opti,\n",
        "                            loss,\n",
        "                            bias,\n",
        "                            drop_rate,\n",
        "                            alpha)\n",
        "        model.to(device)\n",
        "        model_list.append(model)\n",
        "\n",
        "    for i in range(len(model_list)):\n",
        "        model_list[i].load_state_dict(torch.load( model_directory  % i ))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5XdQIBpSxeF"
      },
      "source": [
        "Creating Streams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Qfp24ueJSxeG"
      },
      "outputs": [],
      "source": [
        "stream_list = []\n",
        "for _ in range(ensemble_size):\n",
        "    stream  = torch.cuda.Stream()\n",
        "    stream_list.append(stream)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ6VzvFnSxeH"
      },
      "source": [
        "Creating desired reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "niKHSkhECOE1"
      },
      "outputs": [],
      "source": [
        "desired_reward = torch.ones((1, time_size, reward_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lInxZXYjSxeI"
      },
      "source": [
        "Putting all the previous works into play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-jpi_m6p3RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3deb7137-f8c9-4e91-b29e-aacd98142bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/100000 [02:31<4212:58:36, 151.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 137.0752 seconds\n",
            "Episode 1: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/100000 [05:14<4388:19:23, 157.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 143.6712 seconds\n",
            "Episode 2: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/100000 [07:39<4225:00:31, 152.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 142.0799 seconds\n",
            "Episode 3: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 4/100000 [10:18<4306:06:12, 155.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 146.5756 seconds\n",
            "Episode 4: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 5/100000 [13:09<4468:13:05, 160.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 150.2748 seconds\n",
            "Episode 5: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 6/100000 [15:50<4465:31:56, 160.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 154.3744 seconds\n",
            "Episode 6: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 7/100000 [18:29<4447:37:53, 160.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 150.8139 seconds\n",
            "Episode 7: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 8/100000 [21:07<4430:36:48, 159.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 152.1783 seconds\n",
            "Episode 8: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 9/100000 [23:56<4514:14:26, 162.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 154.2595 seconds\n",
            "Episode 9: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 10/100000 [26:40<4525:16:08, 162.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 154.6665 seconds\n",
            "Episode 10: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 11/100000 [29:57<4812:36:02, 173.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 154.5675 seconds\n",
            "Episode 11: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 12/100000 [33:14<5012:26:52, 180.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 155.2394 seconds\n",
            "Episode 12: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 13/100000 [36:30<5144:46:06, 185.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 154.0773 seconds\n",
            "Episode 13: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 14/100000 [39:46<5234:07:19, 188.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 154.4696 seconds\n",
            "Episode 14: Summed_Reward = 0.0\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
            "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8, 8, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7,\n",
            "        7, 8, 8, 8, 8, 8, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4,\n",
            "        4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 7, 7, 8, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 3, 4, 3, 4, 4,\n",
            "        5, 2, 3, 3, 4, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
            "        6, 6, 7, 7, 7, 8, 8, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 3, 4, 5, 6, 7, 8],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "performance_log  = []\n",
        "\n",
        "for training_episode in tqdm(range(episode_for_training)):\n",
        "\n",
        "    # initializing short term experience replay buffer\n",
        "    list_states  = []\n",
        "    list_actions = []\n",
        "    list_rewards = []\n",
        "\n",
        "    # initializing environment\n",
        "    env                    = gym.make(game_name, is_slippery=False, map_name=\"4x4\")\n",
        "    env._max_episode_steps = max_steps_for_each_episode\n",
        "    state                  = env.reset()\n",
        "    summed_reward          = 0\n",
        "\n",
        "    # observing state\n",
        "    state    = vectorizing_state(state)\n",
        "    list_states.append(state)\n",
        "\n",
        "    for count in itertools.count(1):\n",
        "\n",
        "        print(f'\\rStep: {count}\\r', end='', flush=True)\n",
        "\n",
        "        # initializing and updating action\n",
        "        state                 = torch.tensor(np.atleast_2d(state), dtype=torch.float)\n",
        "        t_oscillation         =  (noise_t if (training_episode % (2 * noise_r_oscillation) < noise_r_oscillation) else 1)\n",
        "        r_oscillation         =  (noise_r if (training_episode % (2 * noise_r_oscillation) < noise_r_oscillation) else 0.000001)\n",
        "        pre_activated_action  = initialize_pre_activated_actions(init,\n",
        "                                                                t_oscillation,\n",
        "                                                                r_oscillation,\n",
        "                                                                (time_size, action_size))\n",
        "        pre_activated_action  = torch.tensor(pre_activated_action[np.newaxis, :, :], dtype=torch.float)\n",
        "        pre_activated_action  = update_pre_activated_actions(iteration_for_deducing,\n",
        "                                                             model_list,\n",
        "                                                             state,\n",
        "                                                             pre_activated_action,\n",
        "                                                             desired_reward,\n",
        "                                                             beta,\n",
        "                                                             device)\n",
        "        action, action_       = vectorizing_action(pre_activated_action)\n",
        "        list_actions.append(action)\n",
        "\n",
        "        # executing action\n",
        "        state, reward, done, info = env.step(action_)\n",
        "\n",
        "        # observing actual reward\n",
        "        summed_reward += reward\n",
        "        reward = vectorizing_reward(state, reward, summed_reward, done, reward_size)\n",
        "        list_rewards.append(reward)\n",
        "\n",
        "        # observing state\n",
        "        state    = vectorizing_state(state)\n",
        "        list_states.append(state)\n",
        "\n",
        "        if done:\n",
        "            print(f'Episode {training_episode}: Summed_Reward = {summed_reward}')\n",
        "            performance_log.append([training_episode, summed_reward])\n",
        "            save_performance_to_csv(performance_log, performance_log_directory)\n",
        "            break\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    env.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # sequentializing short term experience replay buffer\n",
        "    present_state_tensors   ,\\\n",
        "    future_actions_tensors  ,\\\n",
        "    future_rewards_tensors   ,\\\n",
        "    future_states_tensors    ,\\\n",
        "    pad_size_tensors            = sequentialize(list_states  ,\n",
        "                                            list_actions ,\n",
        "                                            list_rewards , chunk_size, device)\n",
        "\n",
        "    # if training_episode == 0:\n",
        "    #   long_term_present_state_tensors   = copy.deepcopy(present_state_tensors  )\n",
        "    #   long_term_future_actions_tensors  = copy.deepcopy(future_actions_tensors )\n",
        "    #   long_term_future_rewards_tensors   = copy.deepcopy(future_rewards_tensors  )\n",
        "    #   long_term_future_states_tensors    = copy.deepcopy(future_states_tensors   )\n",
        "    #   long_term_pad_size_tensors            = copy.deepcopy(pad_size_tensors           )\n",
        "\n",
        "      # storing sequentialized short term experience to long term experience replay buffer by length when it is new\n",
        "      # existing_hashes = set(\n",
        "      #     hash((tuple(t.numpy().flatten()) for t in tensors))\n",
        "      #     for tensors in zip(\n",
        "      #         long_term_present_state_tensors,\n",
        "      #         long_term_future_actions_tensors,\n",
        "      #         long_term_future_rewards_tensors,\n",
        "      #         long_term_future_states_tensors,\n",
        "      #         long_term_pad_size_tensors,\n",
        "      #     )\n",
        "      # )\n",
        "    # else:\n",
        "    #   for i in range(len(present_state_tensors)):\n",
        "    #       new_sample = (\n",
        "    #           present_state_tensors[i],\n",
        "    #           future_actions_tensors[i],\n",
        "    #           future_rewards_tensors[i],\n",
        "    #           future_states_tensors[i],\n",
        "    #           pad_size_tensors[i]\n",
        "    #       )\n",
        "    #       sample_hash = hash(tuple(t.numpy().flatten()) for t in new_sample)\n",
        "    #       if sample_hash not in existing_hashes:\n",
        "#\n",
        "    #           long_term_present_state_tensors  = torch.cat((long_term_present_state_tensors  , new_sample[0].unsqueeze(0)), dim=0)\n",
        "    #           long_term_future_actions_tensors = torch.cat((long_term_future_actions_tensors , new_sample[1].unsqueeze(0)), dim=0)\n",
        "    #           long_term_future_rewards_tensors  = torch.cat((long_term_future_rewards_tensors  , new_sample[2].unsqueeze(0)), dim=0)\n",
        "    #           long_term_future_states_tensors   = torch.cat((long_term_future_states_tensors   , new_sample[3].unsqueeze(0)), dim=0)\n",
        "    #           long_term_pad_size_tensors           = torch.cat((long_term_pad_size_tensors           , new_sample[4].unsqueeze(0)), dim=0)\n",
        "#\n",
        "    #           existing_hashes.add(sample_hash)\n",
        "\n",
        "    if training_episode == 0:\n",
        "        long_term_present_state_tensors   = copy.deepcopy(present_state_tensors  )\n",
        "        long_term_future_actions_tensors  = copy.deepcopy(future_actions_tensors )\n",
        "        long_term_future_rewards_tensors   = copy.deepcopy(future_rewards_tensors  )\n",
        "        long_term_future_states_tensors    = copy.deepcopy(future_states_tensors   )\n",
        "        long_term_pad_size_tensors            = copy.deepcopy(pad_size_tensors           )\n",
        "    else:\n",
        "        for i in range(len(present_state_tensors)):\n",
        "            present_state_tensor   = present_state_tensors    [i]\n",
        "            future_actions_tensor  = future_actions_tensors   [i]\n",
        "            future_rewards_tensor   = future_rewards_tensors    [i]\n",
        "            future_states_tensor    = future_states_tensors     [i]\n",
        "            pad_size_tensor            = pad_size_tensors             [i]\n",
        "            if  not any(torch.all(torch.eq(present_state_tensor  , t)) for t in long_term_present_state_tensors  ) or \\\n",
        "                not any(torch.all(torch.eq(future_actions_tensor , t)) for t in long_term_future_actions_tensors ) or \\\n",
        "                not any(torch.all(torch.eq(future_rewards_tensor  , t)) for t in long_term_future_rewards_tensors  ) or \\\n",
        "                not any(torch.all(torch.eq(future_states_tensor   , t)) for t in long_term_future_states_tensors   ) or \\\n",
        "                not any(torch.all(torch.eq(pad_size_tensor           , t)) for t in long_term_pad_size_tensors           ):\n",
        "                long_term_present_state_tensors  = torch.cat((long_term_present_state_tensors  , present_state_tensor  .unsqueeze(0) ), dim=0)\n",
        "                long_term_future_actions_tensors = torch.cat((long_term_future_actions_tensors , future_actions_tensor .unsqueeze(0) ), dim=0)\n",
        "                long_term_future_rewards_tensors  = torch.cat((long_term_future_rewards_tensors  , future_rewards_tensor  .unsqueeze(0) ), dim=0)\n",
        "                long_term_future_states_tensors   = torch.cat((long_term_future_states_tensors   , future_states_tensor   .unsqueeze(0) ), dim=0)\n",
        "                long_term_pad_size_tensors           = torch.cat((long_term_pad_size_tensors           , pad_size_tensor           .unsqueeze(0) ), dim=0)\n",
        "\n",
        "\n",
        "    # batch offline learning\n",
        "    if (training_episode+1) % batch_size_for_offline_learning == 0:\n",
        "\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "\n",
        "        # training with Prioritized Experience Replay (PER)\n",
        "        for i, model in enumerate(model_list):\n",
        "            with torch.cuda.stream(stream_list[i]):\n",
        "                model                     = update_model(iteration_for_learning,\n",
        "                                                         long_term_present_state_tensors  ,\n",
        "                                                         long_term_future_actions_tensors ,\n",
        "                                                         long_term_future_rewards_tensors  ,\n",
        "                                                         long_term_future_states_tensors   ,\n",
        "                                                         long_term_pad_size_tensors           ,\n",
        "                                                         model,\n",
        "                                                         PER_epsilon,\n",
        "                                                         PER_exponent,\n",
        "                                                         device)\n",
        "                model_list[i]             = model\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "\n",
        "        end_time = time.time()  # Record end time\n",
        "        execution_time = end_time - start_time  # Calculate duration\n",
        "        print(f\"Execution Time: {execution_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "        # saving:\n",
        "        for i in range(len(model_list)):\n",
        "            torch.save(model_list[i].state_dict(), model_directory % i)\n",
        "\n",
        "\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2yunFuFHxgX"
      },
      "source": [
        "# Deducing only\n",
        "Testing mode where your trained agent in the training mode will not learn offline. It just keeps running each episode without learning new stuff."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLG0dkigSxeJ"
      },
      "source": [
        "Loading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvIj0Y-Yf-v_"
      },
      "outputs": [],
      "source": [
        "model_list = []\n",
        "for _ in range(ensemble_size):\n",
        "    model = build_model(state_size,\n",
        "                        hidden_size,\n",
        "                        action_size,\n",
        "                        time_size,\n",
        "                        reward_size,\n",
        "                        neural_type,\n",
        "                        num_layers,\n",
        "                        num_heads,\n",
        "                        hidden_activation,\n",
        "                        output_activation,\n",
        "                        shift,\n",
        "                        init,\n",
        "                        opti,\n",
        "                        loss,\n",
        "                        bias,\n",
        "                        drop_rate,\n",
        "                        alpha)\n",
        "    model.to(device)\n",
        "    model_list.append(model)\n",
        "\n",
        "for i in range(len(model_list)):\n",
        "    model_list[i].load_state_dict(torch.load(model_directory % i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lRIFvTYSxeJ"
      },
      "source": [
        "Creating desired reward ... again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW24TEH7COE2"
      },
      "outputs": [],
      "source": [
        "desired_reward = torch.ones((1, time_size, reward_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R3maKQXSxeR"
      },
      "source": [
        "Putting all the previous works into play ... again\n",
        "\n",
        "But this time the agent does not learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Nw62kaUbHCb"
      },
      "outputs": [],
      "source": [
        "total_summed_reward = 0\n",
        "\n",
        "for testing_episode in range(episode_for_testing):\n",
        "\n",
        "    if render_for_human == True:\n",
        "        env = gym.make( game_name, render_mode=\"human\")\n",
        "    else:\n",
        "        env = gym.make( game_name)\n",
        "    env._max_episode_steps = max_steps_for_each_episode\n",
        "    state                  = env.reset()\n",
        "    if render_for_human == True:\n",
        "        env.render()\n",
        "    summed_reward = 0\n",
        "\n",
        "    state = vectorizing_state(state)\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "\n",
        "        state                 = torch.tensor(np.atleast_2d(state), dtype=torch.float)\n",
        "        pre_activated_action  = initialize_pre_activated_actions(init, noise_t, noise_r, (time_size, action_size))\n",
        "        pre_activated_action  = torch.tensor(pre_activated_action[np.newaxis, :, :], dtype=torch.float)\n",
        "        pre_activated_action  = update_pre_activated_actions(iteration_for_deducing,\n",
        "                                                             model_list,\n",
        "                                                             state,\n",
        "                                                             pre_activated_action,\n",
        "                                                             desired_reward,\n",
        "                                                             beta,\n",
        "                                                             device)\n",
        "        action, action_       = vectorizing_action(pre_activated_action)\n",
        "\n",
        "        state, reward, done,  info = env.step(action_)\n",
        "        if render_for_human == True:\n",
        "            env.render()\n",
        "\n",
        "        summed_reward += reward\n",
        "\n",
        "        state = vectorizing_state(state)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    print(\"Summed reward:\", summed_reward)\n",
        "    print(f'Episode: {testing_episode + 1}')\n",
        "    print('Everaged summed reward:')\n",
        "    total_summed_reward += summed_reward\n",
        "    print(total_summed_reward/(testing_episode + 1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbfiVv3_J1Yx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPyPT-qhrXc6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKTJbMhmZvVI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPHpEEIjf-v_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDqzK4Ht5SF5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Input tensor\n",
        "input_tensor = torch.tensor([4, 2, 3])  # Shape: (3,)\n",
        "\n",
        "# Fixed length for each row\n",
        "fixed_length = 50\n",
        "\n",
        "# Generate a range for the fixed length\n",
        "range_tensor = torch.arange(fixed_length)  # Shape: (fixed_length,)\n",
        "print(range_tensor)\n",
        "# Compare and create the mask\n",
        "output_tensor = (range_tensor < input_tensor.unsqueeze(1)).int()  # Shape: (3, fixed_length)\n",
        "\n",
        "print(output_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Example tensors\n",
        "tensor_3d = torch.randn(2, 3, 999)  # Shape: (batch_size, num_rows, feature_size)\n",
        "print(tensor_3d)\n",
        "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Shape: (batch_size, num_rows)\n",
        "print(tensor_2d)\n",
        "# Expand the 2D tensor to match the 3D tensor's shape for broadcasting\n",
        "tensor_2d_expanded = tensor_2d.unsqueeze(-1)  # Shape: (batch_size, num_rows, 1)\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "result = tensor_3d * tensor_2d_expanded\n",
        "print(result)\n",
        "print(f\"3D Tensor Shape: {tensor_3d.shape}\")\n",
        "print(f\"2D Tensor Shape: {tensor_2d.shape}\")\n",
        "print(f\"Expanded 2D Tensor Shape: {tensor_2d_expanded.shape}\")\n",
        "print(f\"Result Shape: {result.shape}\")\n"
      ],
      "metadata": {
        "id": "wywg2VIgfzX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-bRZFaVhxXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}